{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Optmizacion del modelo"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# importamos las librerías a utilizar\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import roc_auc_score, f1_score, precision_recall_curve,roc_curve,confusion_matrix, ConfusionMatrixDisplay\n",
    "from xgboost import XGBClassifier, plot_importance"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Configuracion de las rutas para lograr las importaciones"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# obtiene la ruta absoluta del directorio 'src' desde la ubicación del notebook\n",
    "src_path = os.path.abspath(os.path.join('..', 'src'))\n",
    "\n",
    "# agrega la ruta a 'src' al sys.path si no está ya presente\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(src_path)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Cargamos los datos pre-procesados"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "df_hotel = pd.read_csv('./../data/processed/hotel_booking.csv')",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Mostramos para chequear\n",
    "df_hotel.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Mostramos información básica\n",
    "df_hotel.describe()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Mostramos información básica\n",
    "df_hotel.info()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Columnas sobre las que trabajar y sus tipo"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardamos las columnas de cada tipo para poder trabajar mas fácil"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# variable objetivo\n",
    "target: str = 'is_canceled'\n",
    "\n",
    "# columnas numéricas\n",
    "col_numericas: list[str] = ['lead_time', 'arrival_date_year', 'arrival_date_week_number', 'arrival_date_day_of_month', 'stays_in_weekend_nights', 'stays_in_week_nights', 'adults', 'children', 'babies', 'is_repeated_guest', 'previous_cancellations', 'previous_bookings_not_canceled', 'booking_changes', 'days_in_waiting_list', 'adr', 'required_car_parking_spaces', 'total_of_special_requests']\n",
    "\n",
    "# columnas categoricas\n",
    "col_categoricas: list[str] = ['hotel', 'arrival_date_month', 'meal', 'country', 'market_segment', 'distribution_channel', 'is_repeated_guest', 'reserved_room_type', 'assigned_room_type', 'deposit_type', 'customer_type']\n",
    "\n",
    "# features\n",
    "features = col_numericas + col_categoricas\n",
    "\n",
    "# agrega a las columnas categoricas la variable objetivo\n",
    "col_categoricas = col_categoricas + [target]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Separamos los datos en entrenamiento y prueba"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from utils import split_my_data\n",
    "\n",
    "\n",
    "# Toma las variables y el target\n",
    "X = df_hotel.drop(columns=target)\n",
    "y = df_hotel[target]\n",
    "\n",
    "# divide the dataset into training and test samples\n",
    "X_train, X_test, y_train, y_test = split_my_data(X, y, test_size=0.2, random_state=42)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Construccion del modelo XGBoost optimizado"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Inicializamos el modelo"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import make_scorer, f1_score, roc_auc_score\n",
    "\n",
    "\n",
    "# Inicializamos el modelo\n",
    "model = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Definimos la estrategia de validacion"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# definir la estrategia de validación cruzada estratificada\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Definimos las metricas e evaluacion"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# definir las métricas de evaluación\n",
    "scoring = {\n",
    "    'f1': make_scorer(f1_score),\n",
    "    'roc_auc': make_scorer(roc_auc_score, needs_proba=True)\n",
    "}"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Creamos la malla de hiperparametros"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# definimos la malla de hiperparametros\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 300, 500, 700],\n",
    "    'learning_rate': [0.01, 0.03, 0.05, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 7, 9],\n",
    "    'subsample': [0.7, 0.8, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.7, 0.8, 0.9],\n",
    "    'gamma': [0, 0.1, 0.2],\n",
    "    'reg_alpha': [0, 0.1, 0.5, 1],\n",
    "    'reg_lambda': [0, 0.1, 0.5, 1],\n",
    "    'scale_pos_weight': [1, 3, 5, 7]\n",
    "}"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Configuramos la búsqueda aleatoria con los parametros construidos"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "random_search = RandomizedSearchCV(\n",
    "    estimator=model,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=50,  # Ajusta el número de iteraciones según tu tiempo\n",
    "    scoring=scoring,\n",
    "    cv=cv,\n",
    "    refit='f1',  # Métrica para seleccionar el mejor modelo\n",
    "    random_state=42,\n",
    "    #n_jobs=-1, Utilizar todos los núcleos disponibles\n",
    "    verbose=2\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Hacemos fit del modelo"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "random_search.fit(X_train, y_train)",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Evaluación del modelo"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Para ver los mejores resultados:\n",
    "print(\"Mejores hiperparámetros:\", random_search.best_params_)\n",
    "print(\"Mejor puntaje F1:\", random_search.best_score_)\n",
    "\n",
    "best_model = random_search.best_estimator_"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Predicciones y evaluación\n",
    "y_pred = model.predict(X_test)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "y_proba = model.predict_proba(X_test)[:, 1]",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Matriz de confusion"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from draw_utils import draw_confusion_matrix\n",
    "\n",
    "\n",
    "# Matriz de confusión\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\nMatriz de confusion:\")\n",
    "draw_confusion_matrix(conf_matrix)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpretación rápida:\n",
    "\n",
    "- True Neg  **(13713)** → Reservas no canceladas predichas correctamente.\n",
    "- True Pos  **(7237)** → Cancelaciones correctamente detectadas.\n",
    "- False Pos **(1194)** → Predijo cancelación, pero la reserva no fue cancelada.\n",
    "- False Neg **(1734)** → No predijo cancelación, pero sí se canceló.\n",
    "\n",
    "Con base en estos números, el modelo está haciendo un trabajo razonable, pero hay margen de mejora en los falsos negativos si nuestro objetivo es minimizar el **churn** (posibilidad de que alguien siga con el servicio)."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Metrica ROC AUC"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Hacemos el estudio de la metrica ROC AUC para verificar el desempeno del modelo. Se sekecciona esta metrica para el estudio debido a que la data se encuentra desbalanceada."
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from draw_utils import draw_roc_auc\n",
    "\n",
    "\n",
    "draw_roc_auc(\n",
    "    y_test=y_test,\n",
    "    y_prob=y_proba,\n",
    "    g_title='Curva ROC - Cancelacion de reservacion'\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Seleccion del mejor threshold"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Para este valor de Auc Roc estudiamos los puntos de corte donde mejor F1-score obtengamos"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# F1 Score por cuantiles\n",
    "df_eval = pd.DataFrame({'true': y_test, 'proba': y_proba})\n",
    "# construimos los thresholds a estudiar\n",
    "thresholds = np.quantile(df_eval['proba'], np.linspace(0.1, 0.9))\n",
    "scores = []\n",
    "\n",
    "for t in thresholds:\n",
    "    # realizamos la prediccion de forma manual con base en\n",
    "    # las probabilidades que se obtienen del modelo\n",
    "    pred = (df_eval['proba'] >= t).astype(int)\n",
    "\n",
    "    #calculamos el f1-score\n",
    "    f1 = f1_score(df_eval['true'], pred)\n",
    "\n",
    "    # guardamos el score\n",
    "    scores.append((t, f1))\n",
    "\n",
    "print(\"\\n📊 --- F1 Score por punto de corte (cuantiles) ---\")\n",
    "for t, f1 in scores:\n",
    "    print(f\"Threshold: {t:.2f} | F1 Score: {f1:.3f}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# seleccionamos el mejor threshold\n",
    "best_threshold = max(scores, key=lambda x: x[1])[0]\n",
    "\n",
    "# realizamos las predicciones con este nuevo threshold de clasificacion\n",
    "y_pred_best_threshold = (y_proba >= best_threshold).astype(int)\n",
    "\n",
    "print(f\"\\n✅ Mejor threshold (F1): {best_threshold:.2f}\")\n",
    "print(f\"F1 Score: {f1_score(y_test, y_pred_best_threshold):.3f}\")\n",
    "print(f\"AUC (el mismo valor visto en la grafica anterior): {roc_auc_score(y_test, y_proba):.3f}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# matriz de confusión con el nuevo threshold\n",
    "conf_matrix_with_opt_f1_score = confusion_matrix(y_test, y_pred_best_threshold)\n",
    "\n",
    "print(\"\\nMatriz de confusion:\")\n",
    "\n",
    "draw_confusion_matrix(conf_matrix_with_opt_f1_score)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Comparamos ambas matrices de confusion, la original y con el nuevo threshold"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from src.draw_utils import draw_comparison_confusion_matrices\n",
    "\n",
    "draw_comparison_confusion_matrices(\n",
    "    confusion_1=conf_matrix,\n",
    "    confusion_2=conf_matrix_with_opt_f1_score,\n",
    "    confusion_matrix_1_name='Modelo default',\n",
    "    confusion_matrix_2_name='Modelo con el threshold que optimiza f1-score'\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Podemos obsevar que con el nuevo threshold se tiene un mejor desempeno con los falsos postivos, valores extremadamente importantes para el modelo. Por lo tanto es mejor utilizar el mdoelo con el threshold encotnrado que maximisa el f1-score."
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Grafico precision - recall"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from draw_utils import draw_pr_auc\n",
    "\n",
    "\n",
    "draw_pr_auc(\n",
    "    y_test=y_test,\n",
    "    y_prob=y_proba,\n",
    "    g_title='Curva ROC - Cancelacion de reservacion'\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Podemos observar que nuestro modelo a tratar de mejorar el Recall disminuye la precision. Por lo tanto, al tratar de mejorar la capacidad del modelo de identificar las personas que cancelaran la capacida de identificar las personas que no cancelan disminuira."
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Interpretacion SHAP"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import shap\n",
    "\n",
    "# interpretación SHAP\n",
    "explainer = shap.Explainer(model, X_train)\n",
    "shap_values = explainer(X_test)\n",
    "shap.summary_plot(shap_values, X_test)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "La variable con mas importancia que podemos ver en este gráfico (deposit_type), es la que tiene mas impacto en el modelo, es decir que los depositos que no se realizaron generan mas probabilidad de cancelación"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Métricas de clasificación\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos observar que el modelo posee buenas métricas con valores de precision, recall y f1-score cercanos por lo tanto parece no existir un alto overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Estudio de la importancia de cada variable"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#Interpretación del modelo – Importancia de Variables\n",
    "import matplotlib.pyplot as plt\n",
    "from xgboost import plot_importance\n",
    "\n",
    "# Visualización de importancia de las características\n",
    "plot_importance(model, max_num_features=10, height=0.5)\n",
    "plt.title(\"Importancia de Variables - XGBoost\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretación de Importancia de Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las top 3 variables que más influyen en la predicción de cancelaciones son:\n",
    "\n",
    "1. lead_time (Tiempo entre reserva y llegada) → cuanto mayor, más riesgo de cancelación.\n",
    "2. adr\t(Precio medio por noche) → precios altos pueden ser más susceptibles a cancelación.\n",
    "3. country\t(Origen del huésped) → posiblemente refleja patrones culturales o restricciones."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Crear DataFrame con importancias\n",
    "feature_importances = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Importance': model.feature_importances_\n",
    "})\n",
    "\n",
    "# Ordenar por importancia descendente\n",
    "feature_importances.sort_values(by='Importance', ascending=False, inplace=True)\n",
    "\n",
    "# Mostrar tabla\n",
    "feature_importances.reset_index(drop=True, inplace=True)\n",
    "feature_importances.head(15)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardamos la gráfica de feature\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Hallazgos clave de la importancia de variables:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Variable                   | Interpretación estratégica para churn |\n",
    "|----------------------------|----------------------------------------|\n",
    "| `deposit_type`             | La más influyente. Si no hay depósito, el cliente puede cancelar sin penalización. Esto **debería revisarse** como política de negocio. |\n",
    "| `required_car_parking_spaces` | Clientes que requieren estacionamiento parecen más comprometidos con su estadía. |\n",
    "| `previous_cancellations`  | Los que han cancelado antes, tienden a hacerlo de nuevo. Perfil de cliente riesgoso. |\n",
    "| `market_segment`          | El canal de origen de la reserva afecta la tasa de cancelación. Canales online (OTA) suelen tener más cancelaciones. |\n",
    "| `total_of_special_requests` | Clientes con solicitudes especiales tienden a ser más fieles. |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En cambio, variables como meal, distribution_channel, y assigned_room_type tienen bajo impacto predictivo en este modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones del modelo de cancelación (churn) con XGBoost\n",
    "\n",
    "**1. Variables más influyentes:**\n",
    "- `deposit_type`: La política de depósito es el factor más determinante. Las reservas sin depósito tienen alta tasa de cancelación.\n",
    "- `required_car_parking_spaces`: Los clientes que solicitan estacionamiento parecen estar más comprometidos.\n",
    "- `previous_cancellations`: El historial del cliente predice comportamiento futuro: quienes ya cancelaron, lo harán de nuevo.\n",
    "\n",
    "**2. Implicancias de negocio:**\n",
    "- Reforzar políticas de depósito mínimo o penalización en segmentos con alta cancelación.\n",
    "- Priorizar promociones hacia segmentos con baja propensión a cancelar (p.ej., quienes hacen solicitudes especiales).\n",
    "- Evaluar y controlar canales de reserva con alto churn (p.ej., ciertos `market_segment` o `distribution_channel`).\n",
    "\n",
    "**3. Recomendaciones adicionales:**\n",
    "- Implementar alertas tempranas para reservas con alto `lead_time` y sin depósito.\n",
    "- Ofrecer beneficios adicionales a clientes frecuentes que nunca han cancelado (`previous_bookings_not_canceled` alto).\n",
    "- Reentrenar el modelo regularmente para adaptarse a cambios de comportamiento por estacionalidad o eventos externos.\n",
    "\n",
    "---\n",
    "\n",
    "✅ El modelo XGBoost ofrece una buena capacidad predictiva y guía acciones concretas para reducir la tasa de cancelaciones.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
